{
  "hash": "7f41b719def719da4d83818b48935d7f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Introduction To Arrow\"\nformat: revealjs\neditor: visual\necho: true\n---\n\n\n## **Learning objectives:**\n\n-   Use {arrow} to load large data files into R efficiently\n-   Partition large data files into parquet files for quicker access, less memory usage, and quicker wrangling\n-   Wrangle {arrow} data using existing {dplyr} operations\n\n## Why learn {arrow}? {.unnumbered}\n\n-   CSV files = very common for ease of access and use\n-   Big/messy CSVs = slow\n-   {arrow} üì¶ reads large datasets quickly & uses {dplyr} syntax\n\n## Packages used {.unnumbered}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(arrow)\nlibrary(curl)\nlibrary(tidyverse)\n```\n:::\n\n\n## Download data {.unnumbered}\n\n-   Case study: [item checkouts dataset from Seattle libraries](https://data.seattle.gov/Community/Checkouts-by-Title/tmmm-ytt6)\n-   **DON'T `download.file()`!!!** (41,389,465 rows of data)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\"https://r4ds.s3.us-west-2.amazonaws.com/seattle-library-checkouts.csv\",}\n  \"data/seattle-library-checkouts.csv\",\n  resume = TRUE\n)\n```\n:::\n\n\n## Open the data {.unnumbered}\n\n-   Size in memory ‚âà 2 √ó size on disk\n-   ~~`read_csv()`~~ ‚û°Ô∏è `arrow::open_dataset()`\n-   Scans a few thousand rows to determine dataset structure\n    -   `ISBN` is empty for 80k rows, so we specify\n-   Does NOT load entire dataset into memory\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseattle_csv <- open_dataset(\n  sources = \"data/seattle-library-checkouts.csv\", \n  col_types = schema(ISBN = string()),\n  format = \"csv\"\n)\n```\n:::\n\n\n## Glimpse the data {.unnumbered}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseattle_csv |> glimpse()\n#> FileSystemDataset with 1 csv file\n#> 41,389,465 rows x 12 columns\n#> $ UsageClass      <string> \"Physical\", \"Physical\", \"Digital\", \"Physical\", \"Ph‚Ä¶\n#> $ CheckoutType    <string> \"Horizon\", \"Horizon\", \"OverDrive\", \"Horizon\", \"Hor‚Ä¶\n#> $ MaterialType    <string> \"BOOK\", \"BOOK\", \"EBOOK\", \"BOOK\", \"SOUNDDISC\", \"BOO‚Ä¶\n#> $ CheckoutYear     <int64> 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 20‚Ä¶\n#> $ CheckoutMonth    <int64> 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,‚Ä¶\n#> $ Checkouts        <int64> 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 2, 3, 2, 1, 3, 2,‚Ä¶\n#> $ Title           <string> \"Super rich : a guide to having it all / Russell S‚Ä¶\n#> $ ISBN            <string> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"‚Ä¶\n#> $ Creator         <string> \"Simmons, Russell\", \"Barclay, James, 1965-\", \"Tim ‚Ä¶\n#> $ Subjects        <string> \"Self realization, Conduct of life, Attitude Psych‚Ä¶\n#> $ Publisher       <string> \"Gotham Books,\", \"Pyr,\", \"Random House, Inc.\", \"Di‚Ä¶\n#> $ PublicationYear <string> \"c2011.\", \"2010.\", \"2015\", \"2005.\", \"c2004.\", \"c20‚Ä¶\n```\n:::\n\n\n## Manipulate the data {.unnumbered}\n\n-   Can use {dplyr} functions on data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseattle_csv |> \n  group_by(CheckoutYear) |> \n  summarise(Checkouts = sum(Checkouts)) |> \n  arrange(CheckoutYear) |> \n  collect()\n#> # A tibble: 18 √ó 2\n#>   CheckoutYear Checkouts\n#>          <int>     <int>\n#> 1         2005   3798685\n#> 2         2006   6599318\n#> 3         2007   7126627\n#> 4         2008   8438486\n#> 5         2009   9135167\n#> 6         2010   8608966\n#> # ‚Ñπ 12 more rows\n```\n:::\n\n\n## Parquet \\> CSV {.unnumbered}\n\n-   Slow: Manipulating large CSV datasets with {readr}\n-   Faster: Manipulating large CSV datasets with {arrow}\n-   Much faster: Manipulating large `parquet` datasets with {arrow}\n    -   Data subdivided into multiple files\n\n## Benefits of parquet {.unnumbered}\n\n-   Smaller files than CSV (efficient encodings + compression)\n-   Stores datatypes (vs CSV storing all as character & guessing)\n-   \"Column-oriented\" (\"thinks\" like a dataframe)\n-   Splits data into chunks you can (often) skip (faster)\n\n**But:**\n\n-   Not human-readable\n\n## Partitioning {.unnumbered}\n\n-   Split data across files so analyses can skip unused data\n-   Experiment to find best partition for your data\n-   Recommendations:\n    -   20 MB \\< Filesize \\< 2 GB\n    -   \\<= 10,000 files\n\n## Seattle library CSV to parquet {.unnumbered}\n\n-   `dplyr::group_by()` to define partitions\n-   `arrow::write_dataset()` to save as parquet\n\n\n::: {.cell}\n\n```{.r .cell-code}\npq_path <- \"data/seattle-library-checkouts\"\nseattle_csv |>\n  group_by(CheckoutYear) |>\n  write_dataset(path = pq_path, format = \"parquet\")\n```\n:::\n\n\n## Seattle library parquet files {.unnumbered}\n\n-   [Apache Hive](https://hive.apache.org/) \"self-describing\" directory/file names\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(\n  files = list.files(pq_path, recursive = TRUE),\n  size_MB = file.size(file.path(pq_path, files)) / 1024^2\n)\n#> # A tibble: 18 √ó 2\n#>   files                            size_MB\n#>   <chr>                              <dbl>\n#> 1 CheckoutYear=2005/part-0.parquet    109.\n#> 2 CheckoutYear=2006/part-0.parquet    164.\n#> 3 CheckoutYear=2007/part-0.parquet    178.\n#> 4 CheckoutYear=2008/part-0.parquet    195.\n#> 5 CheckoutYear=2009/part-0.parquet    214.\n#> 6 CheckoutYear=2010/part-0.parquet    222.\n#> # ‚Ñπ 12 more rows\n```\n:::\n\n\n## parquet + {arrow} + {dplyr} {.unnumbered}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseattle_pq <- open_dataset(pq_path)\nquery <- seattle_pq |> \n  filter(CheckoutYear >= 2018, MaterialType == \"BOOK\") |>\n  group_by(CheckoutYear, CheckoutMonth) |>\n  summarize(TotalCheckouts = sum(Checkouts)) |>\n  arrange(CheckoutYear, CheckoutMonth)\n```\n:::\n\n\n## Results (uncollected) {.unnumbered}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquery\n#> FileSystemDataset (query)\n#> CheckoutYear: int32\n#> CheckoutMonth: int64\n#> TotalCheckouts: int64\n#> \n#> * Grouped by CheckoutYear\n#> * Sorted by CheckoutYear [asc], CheckoutMonth [asc]\n#> See $.data for the source Arrow object\n```\n:::\n\n\n## Results (collected) {.unnumbered}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquery |> collect()\n#> # A tibble: 58 √ó 3\n#> # Groups:   CheckoutYear [5]\n#>   CheckoutYear CheckoutMonth TotalCheckouts\n#>          <int>         <int>          <int>\n#> 1         2018             1         355101\n#> 2         2018             2         309813\n#> 3         2018             3         344487\n#> 4         2018             4         330988\n#> 5         2018             5         318049\n#> 6         2018             6         341825\n#> # ‚Ñπ 52 more rows\n```\n:::\n\n\n## Available verbs {.unnumbered}\n\n-   [`?arrow-dplyr`](https://arrow.apache.org/docs/r/reference/acero.html) for supported functions\n    -   (book uses `?acero` but that's way harder to remember)\n\n## Performance {.unnumbered}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx |> \n  filter(CheckoutYear == 2021, MaterialType == \"BOOK\") |>\n  group_by(CheckoutMonth) |>\n  summarize(TotalCheckouts = sum(Checkouts)) |>\n  arrange(desc(CheckoutMonth)) |>\n  collect() |> \n  system.time()\n```\n:::\n\n\n-   CSV: 11.951s\n-   Parquet: **0.263s**\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}