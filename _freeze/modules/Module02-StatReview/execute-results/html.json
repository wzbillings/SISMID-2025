{
  "hash": "63e8c31ace9a93f808e4fd002968b8af",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Inferential Statistics and Modeling Review\"\necho: TRUE\nformat:\n  revealjs: \n    theme: dark\n    code-line-numbers: false\nbibliography: references.bib\n---\n\n::: {.cell}\n\n:::\n\n\n\n## **Learning objectives:**\n\n-   Develop a statistical hypothesis for a given research question\n\n-   Identify appropriate statistical test for a given hypothesis\n\n-   Implement meaningful code to model data and answer research questions\n\n## Data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqcrc_main <- import(here(\"data\", \"QCRC_FINAL_Deidentified.xlsx\")) %>% \n             mutate(BMI = as.numeric(BMI),\n                    ICU_LOS = as.numeric(ICU_LOS))\nneo <- import(\"https://www.kaggle.com/api/v1/datasets/download/zahrazolghadr/neonatal-hypothermia\")\noptions(scipen = 999) #This sets the numer of digits for p-values so that we can avoid scientific notation\n```\n:::\n\n\n\n## Helpful Package\n\nThe `janitor` package can be helpful in expediting the initial data cleaning that comes along with analysis. One particular function I want to draw your attention to is `clean_names` as it will:\n\n-   replace spaces with underscores\n\n-   make all letters lowercase\n\n-   remove non-standard characters\n\n## Janitor Example\n\nCurrently the names are a bit of a mess:\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Patient_DEID\"     \"Decatur_Transfer\" \"Age\"              \"Female\"          \n[5] \"Race\"             \"Died\"             \"30D_Mortality\"   \n```\n\n\n:::\n:::\n\n\n\nLet's clean them:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqcrc_main <- clean_names(qcrc_main)\n```\n:::\n\n\n\nNow, they are much more manageable:\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"patient_deid\"     \"decatur_transfer\" \"age\"              \"female\"          \n[5] \"race\"             \"died\"             \"x30d_mortality\"  \n```\n\n\n:::\n:::\n\n\n\n## T-test One Sample\n\nHypothesis test used to determine whether the mean calculated from sample data collected from a **single group** is *different* from a **designated value** specified by the researcher\n\n## T-test One Sample Question\n\nIn the QCRC sample, is the average BMI of patients significantly different from the average BMI of the patients examined in the paper, [Associations between body-mass index and COVID-19 severity in 6Â·9 million people in England: a prospective, community-based, cohort study](https://pmc.ncbi.nlm.nih.gov/articles/PMC8081400/) by G.Min Et. Al., of $28.76 kg/m^2$\n\n### Hypothesis\n\n$H_0: \\mu{BMI}_{qcrc} = \\mu{BMI}_{covid}$\n\n$H_A: \\mu{BMI}_{qcrc} \\neq \\mu{BMI}_{covid}$\n\n## T-test One Sample Function\n\nFor all t-test we will use the base R function `t.test`, the `t.test` function will calculate the test and give us basic output\n\nFor a one-sample we must provide two arguments:\n\n-   `x`, the **continuous** data column in the dataset we wish to test against the given mean\n\n-   `mu`, the **given** mean we are comparing against\n\n## T-test One Sample Output\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(x=qcrc_main$bmi, mu=28.76)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  qcrc_main$bmi\nt = 5.7635, df = 284, p-value = 0.00000002144\nalternative hypothesis: true mean is not equal to 28.76\n95 percent confidence interval:\n 30.63377 32.57746\nsample estimates:\nmean of x \n 31.60561 \n```\n\n\n:::\n:::\n\n\n\n## T-Test Two Sample\n\nHypothesis test used to test whether the unknown population **means** of **two groups** are equal or not.\n\n## T-Test Two Sample Question\n\nIs there a statistically significant difference in the BMI of male and female COVID patients in the provided sample of Emory Patients?\n\n### Hypothesis\n\n$H_0: \\mu{BMI}_{males} = \\mu{BMI}_{females}$\n\n$H_A: \\mu{BMI}_{males} \\neq \\mu{BMI}_{females}$\n\n## T-Test Two Sample Function\n\nFor all t-test we will use the base R function `t.test`, the `t.test` function will calculate the test and give us basic output\n\nFor a two-sample we must provide a single argument:\n\n-   `continuous ~ categorical` or `outcome ~ exposure`, formula that models the relationship with your continuous outcome on the left side and two-level categorical variable on the right side separated by a `~`\n\n## T-Test Two Sample Output\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(qcrc_main$bmi~qcrc_main$female)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  qcrc_main$bmi by qcrc_main$female\nt = 1.6845, df = 249.91, p-value = 0.09333\nalternative hypothesis: true difference in means between group Female and group Male is not equal to 0\n95 percent confidence interval:\n -0.2864912  3.6734024\nsample estimates:\nmean in group Female   mean in group Male \n            32.53256             30.83910 \n```\n\n\n:::\n:::\n\n\n\n## T-test Paired\n\nHypothesis test used to determine whether the **mean difference** between **two sets of observations** is zero\n\n## T-test Paired Question\n\nIn the neonatal hypothermia dataset there exist a statistically significant difference in body temperature between time point one (t.1) and time point two (t.2).\n\n### Hypothesis\n\n$H_0: \\mu_{t.2 - t.1} = 0$ or $H_0: \\mu_{t.1 - t.2} = 0$ $H_A: \\mu_{t.2 - t.1} \\ne 0$ or $H_A: \\mu_{t.1 - t.2} \\ne 0$\n\n## T-test Paired Function\n\nFor all t-test we will use the base R function `t.test`, the `t.test` function will calculate the test and give us basic output\n\nFor a paired t-test we must provide three arguments:\n\n-   `x`, the first measurement continuous variable\n\n-   `y`, the second measurement continuous variable\n\n-   `paired = T`, indicator variable to let the function know you want to perform a paired t-test\n\n## T-test Paired Output\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(x=neo$t.1, y=neo$t.2, paired = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPaired t-test\n\ndata:  neo$t.1 and neo$t.2\nt = -22.284, df = 199, p-value < 0.00000000000000022\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -1.1668622 -0.9771378\nsample estimates:\nmean difference \n         -1.072 \n```\n\n\n:::\n:::\n\n\n\n## T-test Paired Output reversed\n\n**Note, a paired t-test looks at magnitude of difference so you can normally ignore the negative signs in the output or reverse the `x` and `y` variables in the arguments**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(x=neo$t.2, y=neo$t.1, paired = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPaired t-test\n\ndata:  neo$t.2 and neo$t.1\nt = 22.284, df = 199, p-value < 0.00000000000000022\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.9771378 1.1668622\nsample estimates:\nmean difference \n          1.072 \n```\n\n\n:::\n:::\n\n\n\n## ANOVA One Way\n\n**An**alysis **o**f **Va**riance\n\nHypothesis test used to analyze the *difference* between the **means** of **more than two groups**\n\n## ANOVA Question\n\nIn the Emory dataset, do we find a statistically significant difference in BMI between racial groups?\n\n### Hypothesis\n\n$H_0: \\mu_{AA} = \\mu_{A} = \\mu_{W} = \\mu_{M}  = \\mu_{U}$\n\n$H_A: At\\; least\\; one\\; \\mu_i\\; differs\\; between\\; the\\; groups$\n\nPlain English: At least one group mean is different from at least one other mean\n\n## ANOVA Function(s)\n\nFor an ANOVA we will use the base R function `aov`, the `aov`function will calculate the test and give us basic output but we need to complement it with the `summary` function to get the full amount of information\n\n**Note, ANOVA only tells you a group is different. Not which group!**\n\nSo, we will also perform a Tukey pairwise comparisons corection to find our different group(s).\n\n## ANOVA Function Arguments\n\nFor an ANOVA using `aov` we need the following argument:\n\n-   `continuous ~ categorical` or `outcome ~ exposure`, formula that models the relationship with your continuous outcome on the left side and 3+ level categorical variable on the right side separated by a `~`\n\nFor the `summary` function we require one argument:\n\n-   `object`, an object created by storing the output of the `aov` function\n\n## ANOVA Output Without `summary`\n\nNotice, no confidence intervals or P-values.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naov(qcrc_main$bmi~qcrc_main$race)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\n   aov(formula = qcrc_main$bmi ~ qcrc_main$race)\n\nTerms:\n                qcrc_main$race Residuals\nSum of Squares        1678.259 18052.692\nDeg. of Freedom              4       280\n\nResidual standard error: 8.029564\nEstimated effects may be unbalanced\n3 observations deleted due to missingness\n```\n\n\n:::\n:::\n\n\n\n## ANOVA Output With `summary`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova <- aov(qcrc_main$bmi~qcrc_main$race)\nsummary(anova)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                Df Sum Sq Mean Sq F value    Pr(>F)    \nqcrc_main$race   4   1678   419.6   6.508 0.0000508 ***\nResiduals      280  18053    64.5                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n3 observations deleted due to missingness\n```\n\n\n:::\n:::\n\n\n\n## ANOVA Multiple Comparisons `TukeyHSD` function\n\nFor `TukeyHSD` we require one argument:\n\n-   `object`, an object created by storing the output of the `aov` function\n\n## ANOVA Output with `TukeyHSD`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTukeyHSD(anova)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = qcrc_main$bmi ~ qcrc_main$race)\n\n$`qcrc_main$race`\n                                                                    diff\nAsian-African American  or Black                              -9.1196581\nCaucasian or White-African American  or Black                 -5.1159544\nMultiple-African American  or Black                           -3.0641026\nUnknown, Unavailable or Unreported-African American  or Black -2.0871795\nCaucasian or White-Asian                                       4.0037037\nMultiple-Asian                                                 6.0555556\nUnknown, Unavailable or Unreported-Asian                       7.0324786\nMultiple-Caucasian or White                                    2.0518519\nUnknown, Unavailable or Unreported-Caucasian or White          3.0287749\nUnknown, Unavailable or Unreported-Multiple                    0.9769231\n                                                                     lwr\nAsian-African American  or Black                              -16.636088\nCaucasian or White-African American  or Black                  -8.506117\nMultiple-African American  or Black                           -25.166827\nUnknown, Unavailable or Unreported-African American  or Black  -6.690034\nCaucasian or White-Asian                                       -3.933860\nMultiple-Asian                                                -17.183251\nUnknown, Unavailable or Unreported-Asian                       -1.493833\nMultiple-Caucasian or White                                   -20.197612\nUnknown, Unavailable or Unreported-Caucasian or White          -2.233779\nUnknown, Unavailable or Unreported-Multiple                   -21.489312\n                                                                    upr\nAsian-African American  or Black                              -1.603228\nCaucasian or White-African American  or Black                 -1.725791\nMultiple-African American  or Black                           19.038622\nUnknown, Unavailable or Unreported-African American  or Black  2.515675\nCaucasian or White-Asian                                      11.941267\nMultiple-Asian                                                29.294363\nUnknown, Unavailable or Unreported-Asian                      15.558790\nMultiple-Caucasian or White                                   24.301316\nUnknown, Unavailable or Unreported-Caucasian or White          8.291328\nUnknown, Unavailable or Unreported-Multiple                   23.443158\n                                                                  p adj\nAsian-African American  or Black                              0.0086325\nCaucasian or White-African American  or Black                 0.0004339\nMultiple-African American  or Black                           0.9955263\nUnknown, Unavailable or Unreported-African American  or Black 0.7249240\nCaucasian or White-Asian                                      0.6378766\nMultiple-Asian                                                0.9528496\nUnknown, Unavailable or Unreported-Asian                      0.1596273\nMultiple-Caucasian or White                                   0.9990901\nUnknown, Unavailable or Unreported-Caucasian or White         0.5113490\nUnknown, Unavailable or Unreported-Multiple                   0.9999539\n```\n\n\n:::\n:::\n\n\n\n## Correlation\n\nThis analysis serves to characterize the relationship between two continuous variable. For instance, if we see an increase in calories do we expect to see an increase in weight. This analysis returns a value $\\rho$ that tells you the strength and direction of the relationship and takes the values \\[-1,1\\] inclusive. A -1 means a strong negative relationship and a 1 means a strong positive relationship. A zero means no relationship. The closer to zero the weaker the relationship\n\nCorrelation is [***NOT***]{.underline} Causation!\n\n## Correlation Question\n\nIs there a relationship between BMI and length of hospital stay in the Emory COVID dataset?\n\n### Hypothesis\n\n$H_0: \\rho = 0$\n\n$H_A: \\rho \\ne 0$\n\n## Correlation Function\n\nFor correlation we will use the base R function `cor.test`, the `cor.test` function will calculate $\\rho$ and give us basic output\n\nFor correlation we must provide three arguments:\n\n-   `x`, the first measurement continuous variable\n\n-   `y`, the second measurement continuous variable\n\n-   `use = \"complete.obs\"`, ignores missing values for the calculation and uses only complete observations (not sure why it doesn't use `na.rm` and yes, it's obnoxious)\n\n## Correlation Output\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor.test(qcrc_main$icu_los, qcrc_main$bmi, use = \"complete.obs\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  qcrc_main$icu_los and qcrc_main$bmi\nt = 3.234, df = 283, p-value = 0.001365\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.07422377 0.29842419\nsample estimates:\n      cor \n0.1887828 \n```\n\n\n:::\n:::\n\n\n\n## Correlation Output Graph Check\n\nAlways check your correlation with a graph to make sure the data is linear\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(qcrc_main, aes(x=bmi, y= icu_los))+\n  geom_point()+\n  geom_smooth(method=\"lm\")+\n  stat_cor()\n```\n\n::: {.cell-output-display}\n![](Module02-StatReview_files/figure-revealjs/unnamed-chunk-14-1.png){width=960}\n:::\n:::\n\n\n\n## Simple Linear Regression\n\nThis analysis is used to characterize the relationship between two continuous variables, where one is treated as the predictor (independent variable) and the other as the outcome (dependent variable). For example, we can analyze whether an increase in calorie intake is associated with an increase in weight. Simple linear regression provides a model to estimate this relationship using a straight-line equation.\n\n## SLR Model Equation\n\n$y = \\beta_0 + \\beta_1x + \\epsilon$\n\n-   $\\beta_1$â: The slope of the line, indicating the strength and direction of the relationship.\n\n-   â$\\beta_0$: The y-intercept, representing the value of $y$ when $x=0$.\n\n-   $\\epsilon$: Random error.\n\nLike correlation, regression does not imply causation! Always interpret results within the study's context and limitations.\n\n## SLR Question\n\nIs BMI (predictor) associated with the length of hospital stay (outcome) in the Emory COVID dataset? Meaning, if BMI changes how much ($\\beta_1$ ) does it change length of stay?\n\n### Hypothesis\n\n$H_0: \\beta_1 = 0$\n\n$H_0: \\beta_1 \\ne 0$\n\n## SLR Function\n\nWe can perform simple linear regression in R using the `lm()` function. Here's how the key components fit:\n\n-   `formula = y ~ x` specifies the dependent and independent variables.\n\n-   `data` specifies the dataset to use.\n\n## SLR Output\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit a simple linear regression model\nmodel <- lm(icu_los ~ bmi, data = qcrc_main)\n\n# Summarize the results\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = icu_los ~ bmi, data = qcrc_main)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-14.180  -6.659  -1.791   4.850  47.637 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)   4.3119     2.0068   2.149  0.03251 * \nbmi           0.1986     0.0614   3.234  0.00137 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.625 on 283 degrees of freedom\n  (3 observations deleted due to missingness)\nMultiple R-squared:  0.03564,\tAdjusted R-squared:  0.03223 \nF-statistic: 10.46 on 1 and 283 DF,  p-value: 0.001365\n```\n\n\n:::\n:::\n\n\n\n## Output Interpretation\n\n-   **Estimate for** $\\beta_1$â: Indicates the expected change in the `icu_los` for a one-unit increase in `bmi`.\n\n-   **P-value**: Tests if $\\beta_1$â is significantly different from 0.\n\n-   $\\mathbf{R^2}$â: Proportion of variance in the outcome explained by the predictor.\n\n## Multiple Linear Regression\n\n\\\nMultiple Linear Regression (MLR) is used to explore and model the relationship between one dependent (outcome) variable and two or more independent (predictor) variables. The goal is to understand how each predictor contributes to the outcome, while controlling for the others.\n\n## MLR Model Equation\n\n$y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_kx_k + \\epsilon$\\\nWhere:\n\n-   $y$: Dependent variable (outcome).\n\n-   $x_1, x_2, \\dots, x_k$â: Independent variables (predictors).\n\n-   $\\beta_0$â: Intercept (value of $y$ when all $x$'s are 0).\n\n-   $\\beta_1, \\beta_2, \\dots, \\beta_kâ$: Regression coefficients, showing the change in $y$ for a one-unit increase in $x$, holding other variables constant.\n\n-   $\\epsilon$: Random error.\n\n## MLR Question\n\nDoes BMI, age, and gender predict the length of hospital stay in the Emory COVID dataset? Or, in another way, how does length of stay change when BMI changes when we ***control*** for age and gender?\n\n### Hypothesis\n\n$H_0:\\beta_{BMI}â\\;=\\;\\beta_{age}\\;â=\\;\\beta_{gender}\\;â=\\;0$\n\n$H_A: At\\; least\\; one\\; \\beta \\neq 0$\n\n## MLR Function\n\nWe can perform multiple linear regression in R using the `lm()` function. Here's how the key components fit:\n\n-   `formula =`$x_1\\;+\\;x_2\\;+\\dots\\;+x_k$ specifies the dependent and independent variables.\n\n-   `data` specifies the dataset to use.\n\n## MLR Output\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit the MLR model\nmodel <- lm(icu_los ~ bmi + female + age, data = qcrc_main)\n\n# Summarize the results\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = icu_los ~ bmi + female + age, data = qcrc_main)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-13.698  -6.211  -1.879   4.690  48.262 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -1.43801    3.69327  -0.389 0.697304    \nbmi          0.24431    0.06588   3.708 0.000251 ***\nfemaleMale   1.62934    1.02860   1.584 0.114310    \nage          0.05374    0.03511   1.530 0.127022    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.586 on 281 degrees of freedom\n  (3 observations deleted due to missingness)\nMultiple R-squared:  0.05116,\tAdjusted R-squared:  0.04103 \nF-statistic: 5.051 on 3 and 281 DF,  p-value: 0.002011\n```\n\n\n:::\n:::\n\n\n\n## MLR Output Interpretation\n\n-   **Coefficients (**$\\beta$**)**: The expected change in $y$ for a one-unit increase in the predictor, holding all other predictors constant..\n\n-   **P-value**: Small p-values (e.g., \\<0.05\\< 0.05\\<0.05) suggest a significant relationship between the predictor and the outcome.\n\n-   **Adjusted** $R^2$: Higher values indicate a better model fit, accounting for the number of predictors.\n\n## Logistic Regression\n\nLogistic regression is used to model the relationship between a binary outcome variable (e.g., \"died\" vs. \"survived\") and one or more predictor variables. It estimates the probability of the outcome occurring based on the predictors.\n\n## Logistic Model Equation\n\nThe logistic regression model predicts the log-odds of the outcome: $\\log\\left(\\frac{p}{1-p}\\right) = \\beta_0 + \\beta_1 \\cdot \\text{female} + \\beta_2 \\cdot \\text{intubated}$\n\nWhere:\n\n-   $p$: Probability of the outcome occurring (e.g., $P(diedÂ =Â 1)$).\n\n-   $\\beta_0$ â: Intercept (log-odds of the outcome when all predictors are 0).\n\n-   $\\beta_1$â: Effect of being female on the log-odds of death, holding intubation status constant.\n\n-   $\\beta_2$â: Effect of being intubated on the log-odds of death, holding gender constant.\n\n## Logistic Question\n\nDoes gender (female) and intubation status predict the likelihood of death in the dataset?\n\n### Hypothesis\n\n-   $H_0:\\beta_{female}\\;â=\\;\\beta_{intubated}\\;â=\\;0$ (Neither gender nor intubation affect the odds of death.)\n\n-   $H_aâ: At\\; least\\; one\\; \\beta \\neq 0$.\n\n## Logistic Function\n\nTo fit a logistic regression model in R, use the `glm()` function with `family = binomial`.\n\n-   **`formula`**: Specifies the model to fit using the syntax: $outcome \\sim x_1 + x_2 +\\dots+x_k$\n\n-   `data` specifies the dataset to use.\n\n-   `family` Specifies the type of regression to perform by defining the error distribution and link function. For logistic regression we use `binomial` but there are also options for `gaussian` and `poisson`\n\n## Logistic Output\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit the logistic regression model\nmodel <- glm(died ~ female + intubated, data = qcrc_main, family = binomial)\n\n# Summarize the results\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = died ~ female + intubated, family = binomial, data = qcrc_main)\n\nCoefficients:\n            Estimate Std. Error z value  Pr(>|z|)    \n(Intercept) -1.27187    0.30248  -4.205 0.0000261 ***\nfemaleMale   0.05613    0.25344   0.221    0.8247    \nintubated    0.75926    0.31004   2.449    0.0143 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 369.34  on 287  degrees of freedom\nResidual deviance: 362.73  on 285  degrees of freedom\nAIC: 368.73\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n\n\n## Logistic IMPORTANT!!\n\nThe $\\beta$s that we get from a logistic regression are useless, you **MUST** exponeniate them for them to be meaningful.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp(coef(model))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)  femaleMale   intubated \n  0.2803069   1.0577398   2.1366863 \n```\n\n\n:::\n:::\n\n\n\n## Logistic Output Interpretation\n\nExample:\n\n-   $\\text{Odds Ratio for Female} = \\exp(0.056) \\approx 1.06$: The odds of death for females are 1.06 times higher than for males.\n\n-   $\\text{Odds Ratio for Intubated} = \\exp(0.759) \\approx 2.13$ : The odds of death for intubated patients are 2.13 times higher than for non-intubated patients.\n",
    "supporting": [
      "Module02-StatReview_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}